{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import skimage.io as sk\n",
    "import cv2\n",
    "import pickle\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.transform import resize\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(741, 3)\n"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv(\"data.csv\")\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Unnamed: 0                                           features  class\n",
      "0             0  [18.973665961010276, 18.027756377319946, 17.08...      2\n",
      "1             1  [43.18564576337837, 42.01190307520001, 40.0499...      2\n",
      "2             2  [42.2965719651132, 41.10960958218893, 40.01249...      2\n",
      "3             3  [43.104524124504614, 42.01190307520001, 41.012...      2\n",
      "4             4  [43.73785545725808, 42.2965719651132, 41.04875...      2\n",
      "..          ...                                                ...    ...\n",
      "736         736  [43.104524124504614, 42.01190307520001, 41.012...      0\n",
      "737         737  [44.04543109109048, 42.0, 41.048751503547585, ...      0\n",
      "738         738  [10.44030650891055, 11.180339887498949, 12.041...      0\n",
      "739         739  [38.01315561749642, 37.013511046643494, 36.055...      0\n",
      "740         740  [43.18564576337837, 42.01190307520001, 41.0487...      0\n",
      "\n",
      "[741 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      2\n",
      "1      2\n",
      "2      2\n",
      "3      2\n",
      "4      2\n",
      "      ..\n",
      "736    0\n",
      "737    0\n",
      "738    0\n",
      "739    0\n",
      "740    0\n",
      "Name: class, Length: 741, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "classes=data[\"class\"]\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'features', 'class'], dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col=data.columns\n",
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m col1\u001b[39m=\u001b[39mcol[\u001b[39m'\u001b[39;49m\u001b[39mfeatures\u001b[39;49m\u001b[39m'\u001b[39;49m]\n\u001b[1;32m      2\u001b[0m \u001b[39mprint\u001b[39m(col1)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexes/base.py:5382\u001b[0m, in \u001b[0;36mIndex.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   5379\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   5380\u001b[0m         key \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(key, dtype\u001b[39m=\u001b[39m\u001b[39mbool\u001b[39m)\n\u001b[0;32m-> 5382\u001b[0m result \u001b[39m=\u001b[39m getitem(key)\n\u001b[1;32m   5383\u001b[0m \u001b[39m# Because we ruled out integer above, we always get an arraylike here\u001b[39;00m\n\u001b[1;32m   5384\u001b[0m \u001b[39mif\u001b[39;00m result\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n",
      "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "col1=col[1:101]\n",
    "print(col1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(741,)\n"
     ]
    }
   ],
   "source": [
    "features=data['features']\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '[18.973665961010276, 18.027756377319946, 17.08800749063506, 16.15549442140351, 14.866068747318506, 14.317821063276353, 13.892443989449804, 13.038404810405298, 12.206555615733702, 10.816653826391969, 9.433981132056603, 8.602325267042627, 7.810249675906654, 7.810249675906654, 8.06225774829855, 9.433981132056603, 8.06225774829855, 7.810249675906654, 7.0710678118654755, 7.810249675906654, 8.602325267042627, 8.94427190999916, 8.54400374531753, 8.246211251235321, 8.06225774829855, 8.0, 8.06225774829855, 8.246211251235321, 7.615773105863909, 6.324555320336759, 5.385164807134504, 4.123105625617661, 5.0, 6.082762530298219, 5.0990195135927845, 4.123105625617661, 3.1622776601683795, 4.123105625617661, 5.0, 4.123105625617661, 4.47213595499958, 5.385164807134504, 6.324555320336759, 7.615773105863909, 8.06225774829855, 8.602325267042627, 8.48528137423857, 9.219544457292887, 9.433981132056603, 8.94427190999916, 9.486832980505138, 10.44030650891055, 11.40175425099138, 12.165525060596439, 13.152946437965905, 14.035668847618199, 13.0, 13.038404810405298, 13.152946437965905, 14.142135623730951, 15.297058540778355, 15.524174696260024, 15.811388300841896, 16.15549442140351, 15.811388300841896, 15.524174696260024, 15.297058540778355, 14.142135623730951, 13.038404810405298, 13.0, 14.035668847618199, 14.142135623730951, 13.152946437965905, 12.36931687685298, 11.40175425099138, 10.44030650891055, 9.848857801796104, 9.433981132056603, 10.0, 9.219544457292887, 9.219544457292887, 8.602325267042627, 8.06225774829855, 8.54400374531753, 9.848857801796104, 11.180339887498949, 10.816653826391969, 11.40175425099138, 12.041594578792296, 12.041594578792296, 12.806248474865697, 13.601470508735444, 12.806248474865697, 12.727922061357855, 12.041594578792296, 11.40175425099138, 11.661903789690601, 11.180339887498949, 11.704699910719626, 10.44030650891055]'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m features:\n\u001b[1;32m      4\u001b[0m     i\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39marray(i)\n\u001b[0;32m----> 5\u001b[0m     i\u001b[39m=\u001b[39mi\u001b[39m.\u001b[39;49mastype(np\u001b[39m.\u001b[39;49mfloat64)\n\u001b[1;32m      6\u001b[0m     p\u001b[39m.\u001b[39mappend(i)\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '[18.973665961010276, 18.027756377319946, 17.08800749063506, 16.15549442140351, 14.866068747318506, 14.317821063276353, 13.892443989449804, 13.038404810405298, 12.206555615733702, 10.816653826391969, 9.433981132056603, 8.602325267042627, 7.810249675906654, 7.810249675906654, 8.06225774829855, 9.433981132056603, 8.06225774829855, 7.810249675906654, 7.0710678118654755, 7.810249675906654, 8.602325267042627, 8.94427190999916, 8.54400374531753, 8.246211251235321, 8.06225774829855, 8.0, 8.06225774829855, 8.246211251235321, 7.615773105863909, 6.324555320336759, 5.385164807134504, 4.123105625617661, 5.0, 6.082762530298219, 5.0990195135927845, 4.123105625617661, 3.1622776601683795, 4.123105625617661, 5.0, 4.123105625617661, 4.47213595499958, 5.385164807134504, 6.324555320336759, 7.615773105863909, 8.06225774829855, 8.602325267042627, 8.48528137423857, 9.219544457292887, 9.433981132056603, 8.94427190999916, 9.486832980505138, 10.44030650891055, 11.40175425099138, 12.165525060596439, 13.152946437965905, 14.035668847618199, 13.0, 13.038404810405298, 13.152946437965905, 14.142135623730951, 15.297058540778355, 15.524174696260024, 15.811388300841896, 16.15549442140351, 15.811388300841896, 15.524174696260024, 15.297058540778355, 14.142135623730951, 13.038404810405298, 13.0, 14.035668847618199, 14.142135623730951, 13.152946437965905, 12.36931687685298, 11.40175425099138, 10.44030650891055, 9.848857801796104, 9.433981132056603, 10.0, 9.219544457292887, 9.219544457292887, 8.602325267042627, 8.06225774829855, 8.54400374531753, 9.848857801796104, 11.180339887498949, 10.816653826391969, 11.40175425099138, 12.041594578792296, 12.041594578792296, 12.806248474865697, 13.601470508735444, 12.806248474865697, 12.727922061357855, 12.041594578792296, 11.40175425099138, 11.661903789690601, 11.180339887498949, 11.704699910719626, 10.44030650891055]'"
     ]
    }
   ],
   "source": [
    "x1=0\n",
    "p=[]\n",
    "for i in features:\n",
    "    i=np.array(i)\n",
    "    i=i.astype(np.float64)\n",
    "    p.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1894\n"
     ]
    }
   ],
   "source": [
    "print(len(features[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Input,GlobalAveragePooling2D,BatchNormalization,GlobalAveragePooling1D\n",
    "from keras.applications import DenseNet121\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Model\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.backend import clear_session\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "x=to_categorical(classes)\n",
    "lb=LabelEncoder()\n",
    "x1=to_categorical(lb.fit_transform(classes))\n",
    "print(x1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n"
     ]
    }
   ],
   "source": [
    "class_val=lb.fit_transform(classes)\n",
    "print(class_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(163, 100)\n"
     ]
    }
   ],
   "source": [
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 256)               25856     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 156)               40092     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 256)               40192     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 256)              1024      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 512)               131584    \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1024)              525312    \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 256)               262400    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 512)               66048     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 512)               131584    \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 128)               65664     \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 2056)              265224    \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 1024)              2106368   \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 256)               262400    \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 4)                 1028      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,158,376\n",
      "Trainable params: 4,156,072\n",
      "Non-trainable params: 2,304\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "clear_session()\n",
    "model=Sequential()\n",
    "model.add(Input(shape=(100)))\n",
    "model.add(Dense(256,activation=\"relu\",kernel_initializer=\"he_uniform\"))\n",
    "model.add(Dense(256,activation=\"relu\",kernel_initializer=\"he_uniform\"))\n",
    "model.add(Dense(156,activation=\"relu\",kernel_initializer=\"he_uniform\"))\n",
    "model.add(Dense(256,activation=\"relu\",kernel_initializer=\"he_uniform\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(512,activation=\"relu\",kernel_initializer=\"he_uniform\"))\n",
    "model.add(Dense(1024,activation=\"relu\",kernel_initializer=\"he_uniform\"))\n",
    "model.add(Dense(256,activation=\"relu\",kernel_initializer=\"he_uniform\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(128,activation=\"relu\",kernel_initializer=\"he_uniform\"))\n",
    "model.add(Dense(512,activation=\"relu\",kernel_initializer=\"he_uniform\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(256,activation=\"relu\",kernel_initializer=\"he_uniform\"))\n",
    "model.add(Dense(512,activation=\"relu\",kernel_initializer=\"he_uniform\"))\n",
    "model.add(Dense(128,activation=\"relu\",kernel_initializer=\"he_uniform\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(2056,activation=\"relu\",kernel_initializer=\"he_uniform\"))\n",
    "model.add(Dense(1024,activation=\"relu\",kernel_initializer=\"he_uniform\"))\n",
    "model.add(Dense(256,activation=\"relu\",kernel_initializer=\"he_uniform\"))\n",
    "model.add(Dense(4,activation=\"softmax\"))\n",
    "model.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ClsModel(n_classes=3, input_shape=(163,100,1)):\n",
    "\n",
    "    model_d=DenseNet121(weights='imagenet',include_top=False, input_shape=(163,100,1)) \n",
    "\n",
    "\n",
    "    x=model_d.output\n",
    "\n",
    "\n",
    "    x= GlobalAveragePooling2D()(x)\n",
    "\n",
    "    x= BatchNormalization()(x)\n",
    "\n",
    "    x= Dropout(0.5)(x)\n",
    "\n",
    "    x= Dense(1024,activation='relu')(x) \n",
    "\n",
    "    x= Dense(512,activation='relu')(x) \n",
    "\n",
    "    x= BatchNormalization()(x)\n",
    "\n",
    "    x= Dropout(0.5)(x)\n",
    "\n",
    "\n",
    "    preds=Dense(n_classes,activation='softmax')(x) #\n",
    "    model=Model(inputs=model_d.input,outputs=preds)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The input must have 3 channels; Received `input_shape=(163, 100, 1)`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[39m=\u001b[39mClsModel(\u001b[39m3\u001b[39;49m,(\u001b[39m163\u001b[39;49m,\u001b[39m100\u001b[39;49m,\u001b[39m1\u001b[39;49m))\n",
      "Cell \u001b[0;32mIn[16], line 3\u001b[0m, in \u001b[0;36mClsModel\u001b[0;34m(n_classes, input_shape)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mClsModel\u001b[39m(n_classes\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, input_shape\u001b[39m=\u001b[39m(\u001b[39m163\u001b[39m,\u001b[39m100\u001b[39m,\u001b[39m1\u001b[39m)):\n\u001b[0;32m----> 3\u001b[0m     model_d\u001b[39m=\u001b[39mDenseNet121(weights\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mimagenet\u001b[39;49m\u001b[39m'\u001b[39;49m,include_top\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, input_shape\u001b[39m=\u001b[39;49m(\u001b[39m163\u001b[39;49m,\u001b[39m100\u001b[39;49m,\u001b[39m1\u001b[39;49m)) \n\u001b[1;32m      6\u001b[0m     x\u001b[39m=\u001b[39mmodel_d\u001b[39m.\u001b[39moutput\n\u001b[1;32m      9\u001b[0m     x\u001b[39m=\u001b[39m GlobalAveragePooling2D()(x)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/applications/densenet.py:358\u001b[0m, in \u001b[0;36mDenseNet121\u001b[0;34m(include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation)\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[39m@keras_export\u001b[39m(\n\u001b[1;32m    346\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mkeras.applications.densenet.DenseNet121\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mkeras.applications.DenseNet121\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    347\u001b[0m )\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    355\u001b[0m     classifier_activation\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msoftmax\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    356\u001b[0m ):\n\u001b[1;32m    357\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Instantiates the Densenet121 architecture.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 358\u001b[0m     \u001b[39mreturn\u001b[39;00m DenseNet(\n\u001b[1;32m    359\u001b[0m         [\u001b[39m6\u001b[39;49m, \u001b[39m12\u001b[39;49m, \u001b[39m24\u001b[39;49m, \u001b[39m16\u001b[39;49m],\n\u001b[1;32m    360\u001b[0m         include_top,\n\u001b[1;32m    361\u001b[0m         weights,\n\u001b[1;32m    362\u001b[0m         input_tensor,\n\u001b[1;32m    363\u001b[0m         input_shape,\n\u001b[1;32m    364\u001b[0m         pooling,\n\u001b[1;32m    365\u001b[0m         classes,\n\u001b[1;32m    366\u001b[0m         classifier_activation,\n\u001b[1;32m    367\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/applications/densenet.py:223\u001b[0m, in \u001b[0;36mDenseNet\u001b[0;34m(blocks, include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation)\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    218\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mIf using `weights` as `\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mimagenet\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m` with `include_top`\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    219\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m as true, `classes` should be 1000\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    220\u001b[0m     )\n\u001b[1;32m    222\u001b[0m \u001b[39m# Determine proper input shape\u001b[39;00m\n\u001b[0;32m--> 223\u001b[0m input_shape \u001b[39m=\u001b[39m imagenet_utils\u001b[39m.\u001b[39;49mobtain_input_shape(\n\u001b[1;32m    224\u001b[0m     input_shape,\n\u001b[1;32m    225\u001b[0m     default_size\u001b[39m=\u001b[39;49m\u001b[39m224\u001b[39;49m,\n\u001b[1;32m    226\u001b[0m     min_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m,\n\u001b[1;32m    227\u001b[0m     data_format\u001b[39m=\u001b[39;49mbackend\u001b[39m.\u001b[39;49mimage_data_format(),\n\u001b[1;32m    228\u001b[0m     require_flatten\u001b[39m=\u001b[39;49minclude_top,\n\u001b[1;32m    229\u001b[0m     weights\u001b[39m=\u001b[39;49mweights,\n\u001b[1;32m    230\u001b[0m )\n\u001b[1;32m    232\u001b[0m \u001b[39mif\u001b[39;00m input_tensor \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     img_input \u001b[39m=\u001b[39m layers\u001b[39m.\u001b[39mInput(shape\u001b[39m=\u001b[39minput_shape)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/applications/imagenet_utils.py:401\u001b[0m, in \u001b[0;36mobtain_input_shape\u001b[0;34m(input_shape, default_size, min_size, data_format, require_flatten, weights)\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    398\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`input_shape` must be a tuple of three integers.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    399\u001b[0m     )\n\u001b[1;32m    400\u001b[0m \u001b[39mif\u001b[39;00m input_shape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m!=\u001b[39m \u001b[39m3\u001b[39m \u001b[39mand\u001b[39;00m weights \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mimagenet\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 401\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    402\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe input must have 3 channels; Received \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    403\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m`input_shape=\u001b[39m\u001b[39m{\u001b[39;00minput_shape\u001b[39m}\u001b[39;00m\u001b[39m`\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    404\u001b[0m     )\n\u001b[1;32m    405\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    406\u001b[0m     input_shape[\u001b[39m0\u001b[39m] \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m input_shape[\u001b[39m0\u001b[39m] \u001b[39m<\u001b[39m min_size\n\u001b[1;32m    407\u001b[0m ) \u001b[39mor\u001b[39;00m (input_shape[\u001b[39m1\u001b[39m] \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m input_shape[\u001b[39m1\u001b[39m] \u001b[39m<\u001b[39m min_size):\n\u001b[1;32m    408\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    409\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mInput size must be at least \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    410\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mmin_size\u001b[39m}\u001b[39;00m\u001b[39mx\u001b[39m\u001b[39m{\u001b[39;00mmin_size\u001b[39m}\u001b[39;00m\u001b[39m; Received: \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    411\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39minput_shape=\u001b[39m\u001b[39m{\u001b[39;00minput_shape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    412\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: The input must have 3 channels; Received `input_shape=(163, 100, 1)`"
     ]
    }
   ],
   "source": [
    "model=ClsModel(3,(163,100,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features=np.array(features).reshape(145,100,1)\n",
    "x_train,x_test,y_train,y_test=train_test_split(features,x1,test_size=0.3,random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "1/1 [==============================] - 7s 7s/step - loss: 2.1674 - accuracy: 0.2632 - val_loss: 134.0394 - val_accuracy: 0.2245\n",
      "Epoch 2/300\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 5.8116 - accuracy: 0.3246 - val_loss: 115.3569 - val_accuracy: 0.2245\n",
      "Epoch 3/300\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 8.7034 - accuracy: 0.3684 - val_loss: 67.8259 - val_accuracy: 0.2857\n",
      "Epoch 4/300\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 4.5967 - accuracy: 0.3947 - val_loss: 36.8002 - val_accuracy: 0.2245\n",
      "Epoch 5/300\n",
      "1/1 [==============================] - 0s 179ms/step - loss: 1.6724 - accuracy: 0.5877 - val_loss: 54.0351 - val_accuracy: 0.2245\n",
      "Epoch 6/300\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 1.6446 - accuracy: 0.3333 - val_loss: 47.5386 - val_accuracy: 0.2245\n",
      "Epoch 7/300\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 1.1603 - accuracy: 0.4123 - val_loss: 28.9123 - val_accuracy: 0.2245\n",
      "Epoch 8/300\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.7946 - accuracy: 0.6930 - val_loss: 12.6045 - val_accuracy: 0.2245\n",
      "Epoch 9/300\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.7963 - accuracy: 0.6491 - val_loss: 6.5220 - val_accuracy: 0.2245\n",
      "Epoch 10/300\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.7301 - accuracy: 0.6930 - val_loss: 9.3521 - val_accuracy: 0.2245\n",
      "Epoch 11/300\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.5577 - accuracy: 0.8158 - val_loss: 16.0463 - val_accuracy: 0.2245\n",
      "Epoch 12/300\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 0.4170 - accuracy: 0.9211 - val_loss: 23.0611 - val_accuracy: 0.2245\n",
      "Epoch 13/300\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.3037 - accuracy: 0.9474 - val_loss: 29.6932 - val_accuracy: 0.2245\n",
      "Epoch 14/300\n",
      "1/1 [==============================] - 0s 180ms/step - loss: 0.2361 - accuracy: 0.9649 - val_loss: 36.0130 - val_accuracy: 0.2245\n",
      "Epoch 15/300\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.1917 - accuracy: 0.9649 - val_loss: 41.3223 - val_accuracy: 0.2245\n",
      "Epoch 16/300\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 0.1304 - accuracy: 0.9912 - val_loss: 45.2580 - val_accuracy: 0.2245\n",
      "Epoch 17/300\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.0834 - accuracy: 0.9912 - val_loss: 48.0504 - val_accuracy: 0.2245\n",
      "Epoch 18/300\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 0.0534 - accuracy: 1.0000 - val_loss: 50.1247 - val_accuracy: 0.2245\n",
      "Epoch 19/300\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 0.0351 - accuracy: 1.0000 - val_loss: 51.4464 - val_accuracy: 0.2245\n",
      "Epoch 20/300\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 0.0214 - accuracy: 1.0000 - val_loss: 52.1200 - val_accuracy: 0.2245\n",
      "Epoch 21/300\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 52.3565 - val_accuracy: 0.2245\n",
      "Epoch 22/300\n",
      "1/1 [==============================] - 0s 221ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 52.3844 - val_accuracy: 0.2245\n",
      "Epoch 23/300\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 52.2049 - val_accuracy: 0.2245\n",
      "Epoch 24/300\n",
      "1/1 [==============================] - 0s 238ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 51.8759 - val_accuracy: 0.2245\n",
      "Epoch 25/300\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 51.4794 - val_accuracy: 0.2245\n",
      "Epoch 26/300\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 51.0036 - val_accuracy: 0.2245\n",
      "Epoch 27/300\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 8.4036e-04 - accuracy: 1.0000 - val_loss: 50.4769 - val_accuracy: 0.2245\n",
      "Epoch 28/300\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 6.3521e-04 - accuracy: 1.0000 - val_loss: 49.9078 - val_accuracy: 0.2245\n",
      "Epoch 29/300\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 4.8941e-04 - accuracy: 1.0000 - val_loss: 49.3114 - val_accuracy: 0.2245\n",
      "Epoch 30/300\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 3.8645e-04 - accuracy: 1.0000 - val_loss: 48.6780 - val_accuracy: 0.2245\n",
      "Epoch 31/300\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 3.1059e-04 - accuracy: 1.0000 - val_loss: 48.0100 - val_accuracy: 0.2245\n",
      "Epoch 32/300\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 2.6702e-04 - accuracy: 1.0000 - val_loss: 47.3110 - val_accuracy: 0.2245\n",
      "Epoch 33/300\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 2.2416e-04 - accuracy: 1.0000 - val_loss: 46.5920 - val_accuracy: 0.2245\n",
      "Epoch 34/300\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 1.9406e-04 - accuracy: 1.0000 - val_loss: 45.8526 - val_accuracy: 0.2245\n",
      "Epoch 35/300\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 1.7318e-04 - accuracy: 1.0000 - val_loss: 45.0909 - val_accuracy: 0.2245\n",
      "Epoch 36/300\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 1.5771e-04 - accuracy: 1.0000 - val_loss: 44.3090 - val_accuracy: 0.2245\n",
      "Epoch 37/300\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 1.4557e-04 - accuracy: 1.0000 - val_loss: 43.5116 - val_accuracy: 0.2245\n",
      "Epoch 38/300\n",
      "1/1 [==============================] - 0s 282ms/step - loss: 1.3334e-04 - accuracy: 1.0000 - val_loss: 42.7052 - val_accuracy: 0.2245\n",
      "Epoch 39/300\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 1.2000e-04 - accuracy: 1.0000 - val_loss: 41.8919 - val_accuracy: 0.2245\n",
      "Epoch 40/300\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 1.0776e-04 - accuracy: 1.0000 - val_loss: 41.0694 - val_accuracy: 0.2245\n",
      "Epoch 41/300\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 9.8530e-05 - accuracy: 1.0000 - val_loss: 40.2406 - val_accuracy: 0.2245\n",
      "Epoch 42/300\n",
      "1/1 [==============================] - 0s 212ms/step - loss: 9.9233e-05 - accuracy: 1.0000 - val_loss: 39.4066 - val_accuracy: 0.2245\n",
      "Epoch 43/300\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 8.0908e-05 - accuracy: 1.0000 - val_loss: 38.5712 - val_accuracy: 0.2245\n",
      "Epoch 44/300\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 7.3970e-05 - accuracy: 1.0000 - val_loss: 37.7389 - val_accuracy: 0.2245\n",
      "Epoch 45/300\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 6.7720e-05 - accuracy: 1.0000 - val_loss: 36.9082 - val_accuracy: 0.2245\n",
      "Epoch 46/300\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 6.2267e-05 - accuracy: 1.0000 - val_loss: 36.0810 - val_accuracy: 0.2245\n",
      "Epoch 47/300\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 5.7483e-05 - accuracy: 1.0000 - val_loss: 35.2568 - val_accuracy: 0.2245\n",
      "Epoch 48/300\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 5.3298e-05 - accuracy: 1.0000 - val_loss: 34.4367 - val_accuracy: 0.2245\n",
      "Epoch 49/300\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 4.9460e-05 - accuracy: 1.0000 - val_loss: 33.6216 - val_accuracy: 0.2245\n",
      "Epoch 50/300\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 4.5773e-05 - accuracy: 1.0000 - val_loss: 32.8140 - val_accuracy: 0.2245\n",
      "Epoch 51/300\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 4.2320e-05 - accuracy: 1.0000 - val_loss: 32.0185 - val_accuracy: 0.2245\n",
      "Epoch 52/300\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 4.0902e-05 - accuracy: 1.0000 - val_loss: 31.2332 - val_accuracy: 0.2245\n",
      "Epoch 53/300\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 3.7054e-05 - accuracy: 1.0000 - val_loss: 30.4545 - val_accuracy: 0.2245\n",
      "Epoch 54/300\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 3.4685e-05 - accuracy: 1.0000 - val_loss: 29.6829 - val_accuracy: 0.2245\n",
      "Epoch 55/300\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 3.2713e-05 - accuracy: 1.0000 - val_loss: 28.9139 - val_accuracy: 0.2245\n",
      "Epoch 56/300\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 3.1029e-05 - accuracy: 1.0000 - val_loss: 28.1535 - val_accuracy: 0.2245\n",
      "Epoch 57/300\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 2.9546e-05 - accuracy: 1.0000 - val_loss: 27.3951 - val_accuracy: 0.2245\n",
      "Epoch 58/300\n",
      "1/1 [==============================] - 0s 271ms/step - loss: 2.8226e-05 - accuracy: 1.0000 - val_loss: 26.6466 - val_accuracy: 0.2245\n",
      "Epoch 59/300\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 2.7015e-05 - accuracy: 1.0000 - val_loss: 25.9137 - val_accuracy: 0.2245\n",
      "Epoch 60/300\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 2.5866e-05 - accuracy: 1.0000 - val_loss: 25.1961 - val_accuracy: 0.2245\n",
      "Epoch 61/300\n",
      "1/1 [==============================] - 0s 253ms/step - loss: 2.4820e-05 - accuracy: 1.0000 - val_loss: 24.4951 - val_accuracy: 0.2245\n",
      "Epoch 62/300\n",
      "1/1 [==============================] - 0s 287ms/step - loss: 2.3869e-05 - accuracy: 1.0000 - val_loss: 23.8103 - val_accuracy: 0.2245\n",
      "Epoch 63/300\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 2.3012e-05 - accuracy: 1.0000 - val_loss: 23.1431 - val_accuracy: 0.2245\n",
      "Epoch 64/300\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 2.2214e-05 - accuracy: 1.0000 - val_loss: 22.4936 - val_accuracy: 0.2245\n",
      "Epoch 65/300\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 2.1477e-05 - accuracy: 1.0000 - val_loss: 21.8551 - val_accuracy: 0.2245\n",
      "Epoch 66/300\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 2.0793e-05 - accuracy: 1.0000 - val_loss: 21.2310 - val_accuracy: 0.2245\n",
      "Epoch 67/300\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 2.0149e-05 - accuracy: 1.0000 - val_loss: 20.6228 - val_accuracy: 0.2245\n",
      "Epoch 68/300\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 1.9557e-05 - accuracy: 1.0000 - val_loss: 20.0274 - val_accuracy: 0.2245\n",
      "Epoch 69/300\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 1.9012e-05 - accuracy: 1.0000 - val_loss: 19.4469 - val_accuracy: 0.2245\n",
      "Epoch 70/300\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 1.8515e-05 - accuracy: 1.0000 - val_loss: 18.8866 - val_accuracy: 0.2245\n",
      "Epoch 71/300\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 1.8054e-05 - accuracy: 1.0000 - val_loss: 18.3409 - val_accuracy: 0.2245\n",
      "Epoch 72/300\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 1.7617e-05 - accuracy: 1.0000 - val_loss: 17.8100 - val_accuracy: 0.2245\n",
      "Epoch 73/300\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 1.7221e-05 - accuracy: 1.0000 - val_loss: 17.2884 - val_accuracy: 0.2245\n",
      "Epoch 74/300\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 1.6848e-05 - accuracy: 1.0000 - val_loss: 16.7771 - val_accuracy: 0.2245\n",
      "Epoch 75/300\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 1.6496e-05 - accuracy: 1.0000 - val_loss: 16.2779 - val_accuracy: 0.2245\n",
      "Epoch 76/300\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 1.6173e-05 - accuracy: 1.0000 - val_loss: 15.7884 - val_accuracy: 0.2245\n",
      "Epoch 77/300\n",
      "1/1 [==============================] - 0s 277ms/step - loss: 1.5857e-05 - accuracy: 1.0000 - val_loss: 15.3103 - val_accuracy: 0.2245\n",
      "Epoch 78/300\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 1.5575e-05 - accuracy: 1.0000 - val_loss: 14.8424 - val_accuracy: 0.2245\n",
      "Epoch 79/300\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 1.5293e-05 - accuracy: 1.0000 - val_loss: 14.3868 - val_accuracy: 0.2245\n",
      "Epoch 80/300\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 1.5037e-05 - accuracy: 1.0000 - val_loss: 13.9404 - val_accuracy: 0.2041\n",
      "Epoch 81/300\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 1.4792e-05 - accuracy: 1.0000 - val_loss: 13.5041 - val_accuracy: 0.2041\n",
      "Epoch 82/300\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 1.4556e-05 - accuracy: 1.0000 - val_loss: 13.0792 - val_accuracy: 0.2041\n",
      "Epoch 83/300\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 1.4339e-05 - accuracy: 1.0000 - val_loss: 12.6677 - val_accuracy: 0.1837\n",
      "Epoch 84/300\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 1.4122e-05 - accuracy: 1.0000 - val_loss: 12.2653 - val_accuracy: 0.1837\n",
      "Epoch 85/300\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 1.3911e-05 - accuracy: 1.0000 - val_loss: 11.8727 - val_accuracy: 0.1837\n",
      "Epoch 86/300\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 1.3710e-05 - accuracy: 1.0000 - val_loss: 11.4897 - val_accuracy: 0.1837\n",
      "Epoch 87/300\n",
      "1/1 [==============================] - 0s 213ms/step - loss: 1.3517e-05 - accuracy: 1.0000 - val_loss: 11.1168 - val_accuracy: 0.1837\n",
      "Epoch 88/300\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 1.3334e-05 - accuracy: 1.0000 - val_loss: 10.7553 - val_accuracy: 0.1837\n",
      "Epoch 89/300\n",
      "1/1 [==============================] - 0s 243ms/step - loss: 1.3152e-05 - accuracy: 1.0000 - val_loss: 10.4074 - val_accuracy: 0.1837\n",
      "Epoch 90/300\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 1.2987e-05 - accuracy: 1.0000 - val_loss: 10.0721 - val_accuracy: 0.1837\n",
      "Epoch 91/300\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 1.2823e-05 - accuracy: 1.0000 - val_loss: 9.7465 - val_accuracy: 0.1837\n",
      "Epoch 92/300\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 1.2661e-05 - accuracy: 1.0000 - val_loss: 9.4346 - val_accuracy: 0.1837\n",
      "Epoch 93/300\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 1.2514e-05 - accuracy: 1.0000 - val_loss: 9.1372 - val_accuracy: 0.1837\n",
      "Epoch 94/300\n",
      "1/1 [==============================] - 0s 204ms/step - loss: 1.2365e-05 - accuracy: 1.0000 - val_loss: 8.8548 - val_accuracy: 0.1837\n",
      "Epoch 95/300\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 1.2220e-05 - accuracy: 1.0000 - val_loss: 8.5851 - val_accuracy: 0.1633\n",
      "Epoch 96/300\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 1.2081e-05 - accuracy: 1.0000 - val_loss: 8.3262 - val_accuracy: 0.1837\n",
      "Epoch 97/300\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 1.1954e-05 - accuracy: 1.0000 - val_loss: 8.0804 - val_accuracy: 0.1837\n",
      "Epoch 98/300\n",
      "1/1 [==============================] - 0s 268ms/step - loss: 1.1817e-05 - accuracy: 1.0000 - val_loss: 7.8482 - val_accuracy: 0.1837\n",
      "Epoch 99/300\n",
      "1/1 [==============================] - 0s 216ms/step - loss: 1.1689e-05 - accuracy: 1.0000 - val_loss: 7.6277 - val_accuracy: 0.1837\n",
      "Epoch 100/300\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 1.1565e-05 - accuracy: 1.0000 - val_loss: 7.4154 - val_accuracy: 0.1837\n",
      "Epoch 101/300\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 1.1441e-05 - accuracy: 1.0000 - val_loss: 7.2127 - val_accuracy: 0.2041\n",
      "Epoch 102/300\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 1.1327e-05 - accuracy: 1.0000 - val_loss: 7.0204 - val_accuracy: 0.2041\n",
      "Epoch 103/300\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 1.1210e-05 - accuracy: 1.0000 - val_loss: 6.8327 - val_accuracy: 0.2245\n",
      "Epoch 104/300\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 1.1100e-05 - accuracy: 1.0000 - val_loss: 6.6536 - val_accuracy: 0.2245\n",
      "Epoch 105/300\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 1.0991e-05 - accuracy: 1.0000 - val_loss: 6.4835 - val_accuracy: 0.2245\n",
      "Epoch 106/300\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 1.0879e-05 - accuracy: 1.0000 - val_loss: 6.3248 - val_accuracy: 0.2449\n",
      "Epoch 107/300\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 1.0775e-05 - accuracy: 1.0000 - val_loss: 6.1752 - val_accuracy: 0.2653\n",
      "Epoch 108/300\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 1.0673e-05 - accuracy: 1.0000 - val_loss: 6.0340 - val_accuracy: 0.2857\n",
      "Epoch 109/300\n",
      "1/1 [==============================] - 0s 236ms/step - loss: 1.0575e-05 - accuracy: 1.0000 - val_loss: 5.9030 - val_accuracy: 0.2857\n",
      "Epoch 110/300\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 1.0475e-05 - accuracy: 1.0000 - val_loss: 5.7811 - val_accuracy: 0.2857\n",
      "Epoch 111/300\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 1.0380e-05 - accuracy: 1.0000 - val_loss: 5.6676 - val_accuracy: 0.2857\n",
      "Epoch 112/300\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 1.0286e-05 - accuracy: 1.0000 - val_loss: 5.5598 - val_accuracy: 0.2857\n",
      "Epoch 113/300\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 1.0194e-05 - accuracy: 1.0000 - val_loss: 5.4607 - val_accuracy: 0.3061\n",
      "Epoch 114/300\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 1.0105e-05 - accuracy: 1.0000 - val_loss: 5.3679 - val_accuracy: 0.3061\n",
      "Epoch 115/300\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 1.0019e-05 - accuracy: 1.0000 - val_loss: 5.2808 - val_accuracy: 0.3265\n",
      "Epoch 116/300\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 9.9318e-06 - accuracy: 1.0000 - val_loss: 5.1992 - val_accuracy: 0.3265\n",
      "Epoch 117/300\n",
      "1/1 [==============================] - 0s 202ms/step - loss: 9.8377e-06 - accuracy: 1.0000 - val_loss: 5.1206 - val_accuracy: 0.3265\n",
      "Epoch 118/300\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 9.7562e-06 - accuracy: 1.0000 - val_loss: 5.0452 - val_accuracy: 0.3469\n",
      "Epoch 119/300\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 9.6715e-06 - accuracy: 1.0000 - val_loss: 4.9719 - val_accuracy: 0.3469\n",
      "Epoch 120/300\n",
      "1/1 [==============================] - 0s 283ms/step - loss: 9.5909e-06 - accuracy: 1.0000 - val_loss: 4.9004 - val_accuracy: 0.3673\n",
      "Epoch 121/300\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 9.5146e-06 - accuracy: 1.0000 - val_loss: 4.8323 - val_accuracy: 0.3673\n",
      "Epoch 122/300\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 9.4299e-06 - accuracy: 1.0000 - val_loss: 4.7685 - val_accuracy: 0.3673\n",
      "Epoch 123/300\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 9.3525e-06 - accuracy: 1.0000 - val_loss: 4.7091 - val_accuracy: 0.3673\n",
      "Epoch 124/300\n",
      "1/1 [==============================] - 0s 217ms/step - loss: 9.2804e-06 - accuracy: 1.0000 - val_loss: 4.6519 - val_accuracy: 0.3673\n",
      "Epoch 125/300\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 9.1999e-06 - accuracy: 1.0000 - val_loss: 4.5970 - val_accuracy: 0.3673\n",
      "Epoch 126/300\n",
      "1/1 [==============================] - 0s 220ms/step - loss: 9.1288e-06 - accuracy: 1.0000 - val_loss: 4.5479 - val_accuracy: 0.3673\n",
      "Epoch 127/300\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 9.0608e-06 - accuracy: 1.0000 - val_loss: 4.5015 - val_accuracy: 0.3469\n",
      "Epoch 128/300\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 8.9876e-06 - accuracy: 1.0000 - val_loss: 4.4578 - val_accuracy: 0.3673\n",
      "Epoch 129/300\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 8.9113e-06 - accuracy: 1.0000 - val_loss: 4.4165 - val_accuracy: 0.3469\n",
      "Epoch 130/300\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 8.8454e-06 - accuracy: 1.0000 - val_loss: 4.3795 - val_accuracy: 0.3469\n",
      "Epoch 131/300\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 8.7764e-06 - accuracy: 1.0000 - val_loss: 4.3435 - val_accuracy: 0.3469\n",
      "Epoch 132/300\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 8.7074e-06 - accuracy: 1.0000 - val_loss: 4.3095 - val_accuracy: 0.3265\n",
      "Epoch 133/300\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 8.6446e-06 - accuracy: 1.0000 - val_loss: 4.2780 - val_accuracy: 0.3265\n",
      "Epoch 134/300\n",
      "1/1 [==============================] - 0s 181ms/step - loss: 8.5746e-06 - accuracy: 1.0000 - val_loss: 4.2505 - val_accuracy: 0.3265\n",
      "Epoch 135/300\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 8.5118e-06 - accuracy: 1.0000 - val_loss: 4.2243 - val_accuracy: 0.3469\n",
      "Epoch 136/300\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 8.4512e-06 - accuracy: 1.0000 - val_loss: 4.1996 - val_accuracy: 0.3469\n",
      "Epoch 137/300\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 8.3843e-06 - accuracy: 1.0000 - val_loss: 4.1775 - val_accuracy: 0.3469\n",
      "Epoch 138/300\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 8.3215e-06 - accuracy: 1.0000 - val_loss: 4.1580 - val_accuracy: 0.3469\n",
      "Epoch 139/300\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 8.2609e-06 - accuracy: 1.0000 - val_loss: 4.1385 - val_accuracy: 0.3469\n",
      "Epoch 140/300\n",
      "1/1 [==============================] - 0s 281ms/step - loss: 8.2023e-06 - accuracy: 1.0000 - val_loss: 4.1209 - val_accuracy: 0.3673\n",
      "Epoch 141/300\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 8.1438e-06 - accuracy: 1.0000 - val_loss: 4.1037 - val_accuracy: 0.3673\n",
      "Epoch 142/300\n",
      "1/1 [==============================] - 0s 199ms/step - loss: 8.0915e-06 - accuracy: 1.0000 - val_loss: 4.0866 - val_accuracy: 0.3673\n",
      "Epoch 143/300\n",
      "1/1 [==============================] - 0s 211ms/step - loss: 8.0319e-06 - accuracy: 1.0000 - val_loss: 4.0721 - val_accuracy: 0.3673\n",
      "Epoch 144/300\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 7.9754e-06 - accuracy: 1.0000 - val_loss: 4.0629 - val_accuracy: 0.3673\n",
      "Epoch 145/300\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 7.9200e-06 - accuracy: 1.0000 - val_loss: 4.0528 - val_accuracy: 0.3673\n",
      "Epoch 146/300\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 7.8656e-06 - accuracy: 1.0000 - val_loss: 4.0472 - val_accuracy: 0.3673\n",
      "Epoch 147/300\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 7.8091e-06 - accuracy: 1.0000 - val_loss: 4.0402 - val_accuracy: 0.3673\n",
      "Epoch 148/300\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 7.7569e-06 - accuracy: 1.0000 - val_loss: 4.0354 - val_accuracy: 0.3673\n",
      "Epoch 149/300\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 7.7004e-06 - accuracy: 1.0000 - val_loss: 4.0315 - val_accuracy: 0.3469\n",
      "Epoch 150/300\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 7.6492e-06 - accuracy: 1.0000 - val_loss: 4.0304 - val_accuracy: 0.3265\n",
      "Epoch 151/300\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 7.5958e-06 - accuracy: 1.0000 - val_loss: 4.0320 - val_accuracy: 0.3469\n",
      "Epoch 152/300\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 7.5477e-06 - accuracy: 1.0000 - val_loss: 4.0348 - val_accuracy: 0.3469\n",
      "Epoch 153/300\n",
      "1/1 [==============================] - 0s 284ms/step - loss: 7.4934e-06 - accuracy: 1.0000 - val_loss: 4.0385 - val_accuracy: 0.3469\n",
      "Epoch 154/300\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 7.4453e-06 - accuracy: 1.0000 - val_loss: 4.0425 - val_accuracy: 0.3469\n",
      "Epoch 155/300\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 7.3951e-06 - accuracy: 1.0000 - val_loss: 4.0475 - val_accuracy: 0.3469\n",
      "Epoch 156/300\n",
      "1/1 [==============================] - 0s 262ms/step - loss: 7.3428e-06 - accuracy: 1.0000 - val_loss: 4.0517 - val_accuracy: 0.3265\n",
      "Epoch 157/300\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 7.2957e-06 - accuracy: 1.0000 - val_loss: 4.0576 - val_accuracy: 0.3265\n",
      "Epoch 158/300\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 7.2518e-06 - accuracy: 1.0000 - val_loss: 4.0642 - val_accuracy: 0.3265\n",
      "Epoch 159/300\n",
      "1/1 [==============================] - 0s 275ms/step - loss: 7.2047e-06 - accuracy: 1.0000 - val_loss: 4.0705 - val_accuracy: 0.3265\n",
      "Epoch 160/300\n",
      "1/1 [==============================] - 0s 218ms/step - loss: 7.1472e-06 - accuracy: 1.0000 - val_loss: 4.0768 - val_accuracy: 0.3265\n",
      "Epoch 161/300\n",
      "1/1 [==============================] - 0s 214ms/step - loss: 7.1044e-06 - accuracy: 1.0000 - val_loss: 4.0830 - val_accuracy: 0.3265\n",
      "Epoch 162/300\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 7.0604e-06 - accuracy: 1.0000 - val_loss: 4.0899 - val_accuracy: 0.3265\n",
      "Epoch 163/300\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 7.0207e-06 - accuracy: 1.0000 - val_loss: 4.0982 - val_accuracy: 0.3265\n",
      "Epoch 164/300\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 6.9716e-06 - accuracy: 1.0000 - val_loss: 4.1071 - val_accuracy: 0.3061\n",
      "Epoch 165/300\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 6.9266e-06 - accuracy: 1.0000 - val_loss: 4.1165 - val_accuracy: 0.3061\n",
      "Epoch 166/300\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 6.8869e-06 - accuracy: 1.0000 - val_loss: 4.1237 - val_accuracy: 0.3061\n",
      "Epoch 167/300\n",
      "1/1 [==============================] - 0s 205ms/step - loss: 6.8482e-06 - accuracy: 1.0000 - val_loss: 4.1277 - val_accuracy: 0.3061\n",
      "Epoch 168/300\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 6.7990e-06 - accuracy: 1.0000 - val_loss: 4.1323 - val_accuracy: 0.3061\n",
      "Epoch 169/300\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 6.7551e-06 - accuracy: 1.0000 - val_loss: 4.1376 - val_accuracy: 0.3061\n",
      "Epoch 170/300\n",
      "1/1 [==============================] - 0s 200ms/step - loss: 6.7185e-06 - accuracy: 1.0000 - val_loss: 4.1441 - val_accuracy: 0.3265\n",
      "Epoch 171/300\n",
      "1/1 [==============================] - 0s 184ms/step - loss: 6.6756e-06 - accuracy: 1.0000 - val_loss: 4.1518 - val_accuracy: 0.3265\n",
      "Epoch 172/300\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 6.6380e-06 - accuracy: 1.0000 - val_loss: 4.1618 - val_accuracy: 0.3265\n",
      "Epoch 173/300\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 6.5920e-06 - accuracy: 1.0000 - val_loss: 4.1715 - val_accuracy: 0.3265\n",
      "Epoch 174/300\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 6.5533e-06 - accuracy: 1.0000 - val_loss: 4.1817 - val_accuracy: 0.3265\n",
      "Epoch 175/300\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 6.5094e-06 - accuracy: 1.0000 - val_loss: 4.1920 - val_accuracy: 0.3469\n",
      "Epoch 176/300\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 6.4728e-06 - accuracy: 1.0000 - val_loss: 4.2028 - val_accuracy: 0.3469\n",
      "Epoch 177/300\n",
      "1/1 [==============================] - 0s 198ms/step - loss: 6.4351e-06 - accuracy: 1.0000 - val_loss: 4.2130 - val_accuracy: 0.3265\n",
      "Epoch 178/300\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 6.3933e-06 - accuracy: 1.0000 - val_loss: 4.2238 - val_accuracy: 0.3061\n",
      "Epoch 179/300\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 6.3619e-06 - accuracy: 1.0000 - val_loss: 4.2356 - val_accuracy: 0.3061\n",
      "Epoch 180/300\n",
      "1/1 [==============================] - 0s 185ms/step - loss: 6.3180e-06 - accuracy: 1.0000 - val_loss: 4.2471 - val_accuracy: 0.3061\n",
      "Epoch 181/300\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 6.2825e-06 - accuracy: 1.0000 - val_loss: 4.2597 - val_accuracy: 0.3061\n",
      "Epoch 182/300\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 6.2427e-06 - accuracy: 1.0000 - val_loss: 4.2722 - val_accuracy: 0.3061\n",
      "Epoch 183/300\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 6.2155e-06 - accuracy: 1.0000 - val_loss: 4.2859 - val_accuracy: 0.3061\n",
      "Epoch 184/300\n",
      "1/1 [==============================] - 0s 183ms/step - loss: 6.1716e-06 - accuracy: 1.0000 - val_loss: 4.3003 - val_accuracy: 0.3061\n",
      "Epoch 185/300\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 6.1361e-06 - accuracy: 1.0000 - val_loss: 4.3147 - val_accuracy: 0.3061\n",
      "Epoch 186/300\n",
      "1/1 [==============================] - 0s 187ms/step - loss: 6.0953e-06 - accuracy: 1.0000 - val_loss: 4.3310 - val_accuracy: 0.3061\n",
      "Epoch 187/300\n",
      "1/1 [==============================] - 0s 201ms/step - loss: 6.0597e-06 - accuracy: 1.0000 - val_loss: 4.3458 - val_accuracy: 0.3061\n",
      "Epoch 188/300\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 6.0273e-06 - accuracy: 1.0000 - val_loss: 4.3598 - val_accuracy: 0.3061\n",
      "Epoch 189/300\n",
      "1/1 [==============================] - 0s 189ms/step - loss: 5.9949e-06 - accuracy: 1.0000 - val_loss: 4.3753 - val_accuracy: 0.3061\n",
      "Epoch 190/300\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 5.9625e-06 - accuracy: 1.0000 - val_loss: 4.3918 - val_accuracy: 0.2857\n",
      "Epoch 191/300\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 5.9269e-06 - accuracy: 1.0000 - val_loss: 4.4069 - val_accuracy: 0.2857\n",
      "Epoch 192/300\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 5.8966e-06 - accuracy: 1.0000 - val_loss: 4.4228 - val_accuracy: 0.2857\n",
      "Epoch 193/300\n",
      "1/1 [==============================] - 0s 186ms/step - loss: 5.8642e-06 - accuracy: 1.0000 - val_loss: 4.4395 - val_accuracy: 0.2653\n",
      "Epoch 194/300\n",
      "1/1 [==============================] - 0s 197ms/step - loss: 5.8318e-06 - accuracy: 1.0000 - val_loss: 4.4569 - val_accuracy: 0.2449\n",
      "Epoch 195/300\n",
      "1/1 [==============================] - 0s 193ms/step - loss: 5.7983e-06 - accuracy: 1.0000 - val_loss: 4.4743 - val_accuracy: 0.2449\n",
      "Epoch 196/300\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 5.7659e-06 - accuracy: 1.0000 - val_loss: 4.4911 - val_accuracy: 0.2449\n",
      "Epoch 197/300\n",
      "1/1 [==============================] - 0s 229ms/step - loss: 5.7335e-06 - accuracy: 1.0000 - val_loss: 4.5076 - val_accuracy: 0.2449\n",
      "Epoch 198/300\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 5.7021e-06 - accuracy: 1.0000 - val_loss: 4.5249 - val_accuracy: 0.2449\n",
      "Epoch 199/300\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 5.6739e-06 - accuracy: 1.0000 - val_loss: 4.5428 - val_accuracy: 0.2449\n",
      "Epoch 200/300\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 5.6425e-06 - accuracy: 1.0000 - val_loss: 4.5620 - val_accuracy: 0.2449\n",
      "Epoch 201/300\n",
      "1/1 [==============================] - 0s 207ms/step - loss: 5.6132e-06 - accuracy: 1.0000 - val_loss: 4.5812 - val_accuracy: 0.2449\n",
      "Epoch 202/300\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 5.5787e-06 - accuracy: 1.0000 - val_loss: 4.5999 - val_accuracy: 0.2449\n",
      "Epoch 203/300\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 5.5484e-06 - accuracy: 1.0000 - val_loss: 4.6175 - val_accuracy: 0.2449\n",
      "Epoch 204/300\n",
      "1/1 [==============================] - 0s 194ms/step - loss: 5.5233e-06 - accuracy: 1.0000 - val_loss: 4.6350 - val_accuracy: 0.2449\n",
      "Epoch 205/300\n",
      "1/1 [==============================] - 0s 196ms/step - loss: 5.4951e-06 - accuracy: 1.0000 - val_loss: 4.6542 - val_accuracy: 0.2449\n",
      "Epoch 206/300\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 5.4595e-06 - accuracy: 1.0000 - val_loss: 4.6740 - val_accuracy: 0.2449\n",
      "Epoch 207/300\n",
      "1/1 [==============================] - 0s 223ms/step - loss: 5.4365e-06 - accuracy: 1.0000 - val_loss: 4.6944 - val_accuracy: 0.2449\n",
      "Epoch 208/300\n",
      "1/1 [==============================] - 0s 191ms/step - loss: 5.4031e-06 - accuracy: 1.0000 - val_loss: 4.7139 - val_accuracy: 0.2449\n",
      "Epoch 209/300\n",
      "1/1 [==============================] - 0s 192ms/step - loss: 5.3811e-06 - accuracy: 1.0000 - val_loss: 4.7324 - val_accuracy: 0.2449\n",
      "Epoch 210/300\n",
      "1/1 [==============================] - 0s 190ms/step - loss: 5.3550e-06 - accuracy: 1.0000 - val_loss: 4.7504 - val_accuracy: 0.2449\n",
      "Epoch 211/300\n",
      "1/1 [==============================] - 0s 206ms/step - loss: 5.3184e-06 - accuracy: 1.0000 - val_loss: 4.7674 - val_accuracy: 0.2449\n",
      "Epoch 212/300\n",
      "1/1 [==============================] - 0s 215ms/step - loss: 5.2974e-06 - accuracy: 1.0000 - val_loss: 4.7864 - val_accuracy: 0.2449\n",
      "Epoch 213/300\n",
      "1/1 [==============================] - 0s 290ms/step - loss: 5.2671e-06 - accuracy: 1.0000 - val_loss: 4.8051 - val_accuracy: 0.2449\n",
      "Epoch 214/300\n",
      "1/1 [==============================] - 0s 226ms/step - loss: 5.2389e-06 - accuracy: 1.0000 - val_loss: 4.8227 - val_accuracy: 0.2449\n",
      "Epoch 215/300\n",
      "1/1 [==============================] - 0s 172ms/step - loss: 5.2148e-06 - accuracy: 1.0000 - val_loss: 4.8396 - val_accuracy: 0.2653\n",
      "Epoch 216/300\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 5.1918e-06 - accuracy: 1.0000 - val_loss: 4.8557 - val_accuracy: 0.2653\n",
      "Epoch 217/300\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 5.1636e-06 - accuracy: 1.0000 - val_loss: 4.8718 - val_accuracy: 0.2653\n",
      "Epoch 218/300\n",
      "1/1 [==============================] - 0s 173ms/step - loss: 5.1385e-06 - accuracy: 1.0000 - val_loss: 4.8886 - val_accuracy: 0.2653\n",
      "Epoch 219/300\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.1082e-06 - accuracy: 1.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[74], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[39m.\u001b[39;49mfit(x_train,y_train,verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,batch_size\u001b[39m=\u001b[39;49m\u001b[39m200\u001b[39;49m,epochs\u001b[39m=\u001b[39;49m\u001b[39m300\u001b[39;49m,validation_data\u001b[39m=\u001b[39;49m[x_test,y_test])\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/engine/training.py:1694\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1679\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m_eval_data_handler\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1680\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_eval_data_handler \u001b[39m=\u001b[39m data_adapter\u001b[39m.\u001b[39mget_data_handler(\n\u001b[1;32m   1681\u001b[0m         x\u001b[39m=\u001b[39mval_x,\n\u001b[1;32m   1682\u001b[0m         y\u001b[39m=\u001b[39mval_y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1692\u001b[0m         steps_per_execution\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_steps_per_execution,\n\u001b[1;32m   1693\u001b[0m     )\n\u001b[0;32m-> 1694\u001b[0m val_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mevaluate(\n\u001b[1;32m   1695\u001b[0m     x\u001b[39m=\u001b[39;49mval_x,\n\u001b[1;32m   1696\u001b[0m     y\u001b[39m=\u001b[39;49mval_y,\n\u001b[1;32m   1697\u001b[0m     sample_weight\u001b[39m=\u001b[39;49mval_sample_weight,\n\u001b[1;32m   1698\u001b[0m     batch_size\u001b[39m=\u001b[39;49mvalidation_batch_size \u001b[39mor\u001b[39;49;00m batch_size,\n\u001b[1;32m   1699\u001b[0m     steps\u001b[39m=\u001b[39;49mvalidation_steps,\n\u001b[1;32m   1700\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m   1701\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[1;32m   1702\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[1;32m   1703\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[1;32m   1704\u001b[0m     return_dict\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1705\u001b[0m     _use_cached_eval_dataset\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1706\u001b[0m )\n\u001b[1;32m   1707\u001b[0m val_logs \u001b[39m=\u001b[39m {\n\u001b[1;32m   1708\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mval_\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m name: val \u001b[39mfor\u001b[39;00m name, val \u001b[39min\u001b[39;00m val_logs\u001b[39m.\u001b[39mitems()\n\u001b[1;32m   1709\u001b[0m }\n\u001b[1;32m   1710\u001b[0m epoch_logs\u001b[39m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/engine/training.py:2032\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   2030\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_test_counter\u001b[39m.\u001b[39massign(\u001b[39m0\u001b[39m)\n\u001b[1;32m   2031\u001b[0m callbacks\u001b[39m.\u001b[39mon_test_begin()\n\u001b[0;32m-> 2032\u001b[0m \u001b[39mfor\u001b[39;00m _, iterator \u001b[39min\u001b[39;00m data_handler\u001b[39m.\u001b[39menumerate_epochs():  \u001b[39m# Single epoch.\u001b[39;00m\n\u001b[1;32m   2033\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreset_metrics()\n\u001b[1;32m   2034\u001b[0m     \u001b[39mwith\u001b[39;00m data_handler\u001b[39m.\u001b[39mcatch_stop_iteration():\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/engine/data_adapter.py:1304\u001b[0m, in \u001b[0;36mDataHandler.enumerate_epochs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Yields `(epoch, tf.data.Iterator)`.\"\"\"\u001b[39;00m\n\u001b[1;32m   1303\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_truncate_execution_to_epoch():\n\u001b[0;32m-> 1304\u001b[0m     data_iterator \u001b[39m=\u001b[39m \u001b[39miter\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset)\n\u001b[1;32m   1305\u001b[0m     \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_initial_epoch, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_epochs):\n\u001b[1;32m   1306\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_insufficient_data:  \u001b[39m# Set by `catch_stop_iteration`.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py:499\u001b[0m, in \u001b[0;36mDatasetV2.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[39mif\u001b[39;00m context\u001b[39m.\u001b[39mexecuting_eagerly() \u001b[39mor\u001b[39;00m ops\u001b[39m.\u001b[39minside_function():\n\u001b[1;32m    498\u001b[0m   \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39mcolocate_with(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variant_tensor):\n\u001b[0;32m--> 499\u001b[0m     \u001b[39mreturn\u001b[39;00m iterator_ops\u001b[39m.\u001b[39;49mOwnedIterator(\u001b[39mself\u001b[39;49m)\n\u001b[1;32m    500\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    501\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m`tf.data.Dataset` only supports Python-style \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    502\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39miteration in eager mode or within tf.function.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/data/ops/iterator_ops.py:703\u001b[0m, in \u001b[0;36mOwnedIterator.__init__\u001b[0;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[1;32m    699\u001b[0m   \u001b[39mif\u001b[39;00m (components \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m element_spec \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    700\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    701\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWhen `dataset` is provided, `element_spec` and `components` must \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    702\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mnot be specified.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 703\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_iterator(dataset)\n\u001b[1;32m    705\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_next_call_count \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/data/ops/iterator_ops.py:742\u001b[0m, in \u001b[0;36mOwnedIterator._create_iterator\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    739\u001b[0m   \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(fulltype\u001b[39m.\u001b[39margs[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39margs[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39margs) \u001b[39m==\u001b[39m \u001b[39mlen\u001b[39m(\n\u001b[1;32m    740\u001b[0m       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flat_output_types)\n\u001b[1;32m    741\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator_resource\u001b[39m.\u001b[39mop\u001b[39m.\u001b[39mexperimental_set_type(fulltype)\n\u001b[0;32m--> 742\u001b[0m gen_dataset_ops\u001b[39m.\u001b[39;49mmake_iterator(ds_variant, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_iterator_resource)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/ops/gen_dataset_ops.py:3409\u001b[0m, in \u001b[0;36mmake_iterator\u001b[0;34m(dataset, iterator, name)\u001b[0m\n\u001b[1;32m   3407\u001b[0m \u001b[39mif\u001b[39;00m tld\u001b[39m.\u001b[39mis_eager:\n\u001b[1;32m   3408\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3409\u001b[0m     _result \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_FastPathExecute(\n\u001b[1;32m   3410\u001b[0m       _ctx, \u001b[39m\"\u001b[39;49m\u001b[39mMakeIterator\u001b[39;49m\u001b[39m\"\u001b[39;49m, name, dataset, iterator)\n\u001b[1;32m   3411\u001b[0m     \u001b[39mreturn\u001b[39;00m _result\n\u001b[1;32m   3412\u001b[0m   \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(x_train,y_train,verbose=1,batch_size=200,epochs=300,validation_data=[x_test,y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 7ms/step\n",
      "[[4.46619928e-01 2.60636210e-02 3.65417331e-01 1.61899194e-01]\n",
      " [4.01569605e-02 1.31290604e-03 9.58051980e-01 4.78139613e-04]\n",
      " [3.74480426e-01 2.01727636e-02 3.75653058e-01 2.29693651e-01]\n",
      " [6.62195757e-02 6.39304638e-01 1.18855517e-02 2.82590270e-01]\n",
      " [7.43736088e-01 6.47221517e-04 1.05207302e-01 1.50409341e-01]\n",
      " [2.81648606e-01 4.68323706e-03 7.13267863e-01 4.00283490e-04]\n",
      " [6.53272033e-01 2.59265840e-01 4.15185727e-02 4.59435768e-02]\n",
      " [2.87526231e-02 2.88291097e-01 4.77536488e-03 6.78180873e-01]\n",
      " [6.57477826e-02 4.23005287e-04 9.01544690e-01 3.22845094e-02]\n",
      " [9.79400754e-01 8.31850059e-03 6.59077289e-03 5.69008756e-03]\n",
      " [4.17267047e-02 8.00447464e-01 1.48622289e-01 9.20352153e-03]\n",
      " [7.40106963e-03 2.15615524e-04 9.64947402e-01 2.74359658e-02]\n",
      " [9.01690349e-02 1.34398997e-01 6.64174616e-01 1.11257434e-01]\n",
      " [4.83463518e-02 8.48282993e-01 5.16440580e-03 9.82062593e-02]\n",
      " [1.70050740e-01 5.71487285e-02 4.37201113e-01 3.35599333e-01]\n",
      " [5.19373380e-02 8.64666283e-01 7.28302170e-04 8.26679394e-02]\n",
      " [2.03964338e-02 2.07369924e-02 4.09422845e-01 5.49443781e-01]\n",
      " [3.87784763e-04 3.76076205e-04 9.99055803e-01 1.80304851e-04]\n",
      " [2.42933136e-04 6.97721436e-04 2.21263384e-04 9.98838127e-01]\n",
      " [9.98636901e-01 2.25070326e-04 1.03218004e-03 1.05830426e-04]\n",
      " [3.33870790e-04 9.99229193e-01 1.04389010e-05 4.26485552e-04]\n",
      " [9.99075651e-01 3.88837536e-04 2.13277832e-04 3.22160631e-04]\n",
      " [9.98622477e-01 2.51342310e-04 9.41842736e-04 1.84303455e-04]\n",
      " [9.98847902e-01 2.16000844e-04 6.56012562e-04 2.80140492e-04]\n",
      " [9.99100089e-01 5.33040380e-04 2.47964228e-04 1.18975666e-04]\n",
      " [5.11459541e-04 2.34157647e-04 2.82611843e-04 9.98971701e-01]\n",
      " [6.72357128e-05 4.13988309e-05 9.99286413e-01 6.04918343e-04]\n",
      " [7.14637223e-04 9.97942865e-01 6.64838823e-04 6.77601900e-04]\n",
      " [2.09571270e-04 3.03022127e-04 3.60691512e-04 9.99126673e-01]\n",
      " [9.42675251e-05 7.78006797e-04 3.24848632e-04 9.98802900e-01]\n",
      " [4.28755186e-04 1.75051420e-04 7.79654438e-05 9.99318182e-01]\n",
      " [1.46184917e-04 9.99494374e-01 1.09111985e-04 2.50214449e-04]\n",
      " [2.21723050e-04 9.99142170e-01 4.38724353e-04 1.97370333e-04]\n",
      " [4.91112412e-04 4.41125667e-06 9.99309123e-01 1.95197106e-04]\n",
      " [9.99265313e-01 4.36263857e-04 1.50910448e-04 1.47582701e-04]\n",
      " [2.08157027e-04 4.85311393e-05 9.99577463e-01 1.65842866e-04]\n",
      " [6.52779185e-04 9.98821795e-01 2.28271776e-04 2.97153776e-04]\n",
      " [1.34748581e-04 9.99541342e-01 1.80410625e-05 3.05922906e-04]\n",
      " [1.02806080e-04 9.99832869e-01 1.25508996e-05 5.16910877e-05]\n",
      " [5.68826916e-04 1.96456429e-04 1.84625373e-04 9.99050081e-01]\n",
      " [9.97986138e-01 7.95761764e-04 8.64112924e-04 3.53889336e-04]\n",
      " [6.05259193e-05 2.84172507e-04 3.23851884e-04 9.99331415e-01]\n",
      " [1.87315367e-04 1.89142389e-04 9.99333560e-01 2.89949850e-04]\n",
      " [5.15631051e-04 1.75523004e-04 9.99262929e-01 4.59471339e-05]\n",
      " [2.35112850e-04 3.98510965e-05 3.78104276e-04 9.99346912e-01]\n",
      " [9.99247551e-01 2.28242352e-04 4.89834929e-04 3.43701031e-05]\n",
      " [4.88567923e-04 3.03567522e-05 9.99209702e-01 2.71414727e-04]\n",
      " [9.98652160e-01 6.23372965e-04 3.70045978e-04 3.54478252e-04]\n",
      " [4.36470837e-05 3.09110823e-04 5.36363979e-04 9.99110878e-01]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "pred=model.predict(x_test)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 2, 1, 0, 2, 0, 3, 2, 0, 1, 2, 2, 1, 2, 1, 3, 2, 3, 0, 1, 0, 0, 0, 0, 3, 2, 1, 3, 3, 3, 1, 1, 2, 0, 2, 1, 1, 1, 3, 0, 3, 2, 2, 3, 0, 2, 0, 3]\n"
     ]
    }
   ],
   "source": [
    "prediction=[]\n",
    "for i in pred:\n",
    "    prediction.append(np.argmax(i))\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 2, 3, 1, 2, 0, 3, 1, 2, 3, 0, 2, 0, 1, 0, 0, 3, 2, 3, 0, 1, 0, 0, 0, 0, 3, 2, 1, 3, 3, 3, 1, 1, 2, 0, 2, 1, 1, 1, 3, 0, 3, 2, 2, 3, 0, 2, 0, 3]\n"
     ]
    }
   ],
   "source": [
    "expected=[]\n",
    "for j in y_test:\n",
    "    j=list(j)\n",
    "    expected.append(j.index(1))\n",
    "print(expected)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7755102040816326\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(expected,prediction))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
